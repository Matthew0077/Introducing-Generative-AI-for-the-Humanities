{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# HW7_èªéŸ³æ¨¡å‹"
      ],
      "metadata": {
        "id": "chNO93gjnhue"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## âœ… ä»»å‹™ä¸€ï¼šèªéŸ³è½‰æ–‡å­— + æ‘˜è¦ï¼ˆASR + Summarizationï¼‰(50%)\n",
        "\n",
        "### ğŸ“Œ ä»»å‹™èªªæ˜ï¼š\n",
        "1. ä½¿ç”¨ Whisper æ¨¡å‹ï¼ˆå»ºè­°ï¼š`openai/whisper-small`ï¼‰å°‡ä¸€æ®µæŒ‡å®šèªéŸ³æª”è½‰æ›æˆæ–‡å­—ã€‚\n",
        "2. ä½¿ç”¨æ–‡å­—æ‘˜è¦æ¨¡å‹ï¼ˆå»ºè­°ï¼š`Pegasus` æˆ– `T5`ï¼‰å°è½‰éŒ„å¾Œçš„æ–‡å­—é€²è¡Œè‡ªå‹•æ‘˜è¦ã€‚\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ“¤ ä½œæ¥­ç¹³äº¤å…§å®¹ï¼š\n",
        "\n",
        "#### ä¸€ã€æ¨¡å‹ç”Ÿæˆçš„æ–‡å­—å…§å®¹\n",
        "\n",
        "#### äºŒã€LLM ç”Ÿæˆçš„æ‘˜è¦ï¼ˆé™ 1ï½3 å¥ï¼‰\n",
        "\n",
        "#### ä¸‰ã€å›ç­”å•é¡Œï¼š\n",
        "\n",
        "- ä½ è¦ºå¾—èªéŸ³è½‰æ–‡å­—çš„æº–ç¢ºåº¦å¦‚ä½•ï¼Ÿæœ‰å“ªäº›åœ°æ–¹è¾¨è­˜å¾—ä¸å¤ å¥½ï¼Ÿå¯èƒ½åŸå› æ˜¯ä»€éº¼ï¼Ÿ\n",
        "- ç”Ÿæˆçš„æ‘˜è¦æœ‰æŠ“åˆ°é‡é»å—ï¼Ÿå“ªäº›åœ°æ–¹å¯ä»¥æ”¹é€²ï¼Ÿ"
      ],
      "metadata": {
        "id": "mrnCW91tpoZa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "éŸ³æª”é€£çµ\n",
        "https://drive.google.com/file/d/1V7MT56GThk0-ONClr_EFsi_Mo2jBHKXI/view?usp=drive_link"
      ],
      "metadata": {
        "id": "A3hrIRemxVAi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture install_logs\n",
        "!apt install ffmpeg\n",
        "!pip install autoawq ffmpeg wavio\n",
        "!pip install gradio\n",
        "!pip install f5-tts # https://github.com/SWivid/F5-TTS/tree/main"
      ],
      "metadata": {
        "id": "XMKcidNqRWIw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. å®‰è£å¿…è¦å¥—ä»¶\n",
        "!pip install gdown openai-whisper transformers sentencepiece --quiet"
      ],
      "metadata": {
        "id": "qCITLWFAgeDo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8058ff76-ffe3-4048-f180-b57a0c6bfe13"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/800.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91mâ”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m204.8/800.5 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m \u001b[32m798.7/800.5 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m800.5/800.5 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. è‡ªå‹•ä¸‹è¼‰éŸ³æª”\n",
        "!gdown 1V7MT56GThk0-ONClr_EFsi_Mo2jBHKXI -O hw7_lecture.m4a\n",
        "audio_path = \"hw7_lecture.m4a\"\n",
        "print(\"å·²ä¸‹è¼‰ï¼š\", audio_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_tsI8Fqjm7I",
        "outputId": "3c65e5c5-182a-4c00-eaa6-59e66571706b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1V7MT56GThk0-ONClr_EFsi_Mo2jBHKXI\n",
            "To: /content/hw7_lecture.m4a\n",
            "\r  0% 0.00/533k [00:00<?, ?B/s]\r100% 533k/533k [00:00<00:00, 29.8MB/s]\n",
            "å·²ä¸‹è¼‰ï¼š hw7_lecture.m4a\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Whisper ASR è½‰éŒ„\n",
        "import whisper\n",
        "asr_model = whisper.load_model(\"small\")\n",
        "result = asr_model.transcribe(audio_path, language=\"zh\")\n",
        "transcript = result[\"text\"]\n",
        "print(\"=== è½‰éŒ„çµæœ ===\")\n",
        "print(transcript)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rNG5jlQUjuDI",
        "outputId": "28ec8095-0c9f-4805-fd52-cff2ce6e9d57"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 461M/461M [00:10<00:00, 44.1MiB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== è½‰éŒ„çµæœ ===\n",
            "èªéŸ³è™•ç†æœ‰å¹¾å€‹æ‡‰ç”¨æˆ–æ˜¯å¹¾å€‹ä»»å‹™æ¯”è¼ƒæ˜é¡¯å°±æ˜¯ç¬¬ä¸€å€‹æˆ‘å€‘å‰›å‰›æœ‰çœ‹åˆ°çš„å°±æ˜¯èªéŸ³è¾¨è­˜é€™æ˜¯ä¸€å€‹å¾ˆé‡è¦çš„ä¸€å€‹ä»»å‹™å°±æ˜¯ç›´è¦ºæƒ³å¾ˆç°¡å–®å°±æ˜¯ä¸€æ®µè²éŸ³ç¶“éé€™å€‹èªéŸ³è¾¨è­˜ç³»çµ±é‚„è¦èƒ½å¤ ç”¢ç”Ÿæ–‡å­—å°ä¸å° é‚£æˆ‘å€‘å‰›å‰›è¬›çš„æ™‚å€™å®ƒåˆ°åº•æ€éº¼åšçš„æˆ‘å€‘å°±è¦æŠŠé‚£å€‹è²éŸ³æŠŠå®ƒæ•´å€‹æ•¸ä½åŒ–ç„¶å¾Œå†è½‰æˆMayerå¹³è­œç„¶å¾Œåˆ©ç”¨ä¸€å€‹èªéŸ³æ¨¡å‹å†æŠŠå®ƒæ•´æ•¸æ–‡å­—ä¾†è¬›åˆ°é€™å€‹æœ‰ä¸€å€‹Odacityæ•´å€‹æˆ‘åˆ—åœ¨é€™é‚Šä¹Ÿæ˜¯æ¨è–¦å¤§å®¶ç­‰ä¸€ä¸‹å¦‚æœä½ ä¸çŸ¥é“æœ‰ä»€éº¼å°±å‡è¨­ä½ æ˜¯æ²’æœ‰ç‰¹åˆ¥çš„å°ˆæ¥­éŒ„éŸ³çš„è€ƒé‡çš„è©±å®ƒç®—æ˜¯ä¸€å€‹è™•ç†éŒ„è£½è™•ç†è²éŸ³è »å¥½çš„ä¸€å€‹å·¥å…·é€™å€‹æ˜¯ä¸€å€‹å…è²»å¯ä»¥ä½¿ç”¨çš„ä¸€å€‹å·¥å…·è¬ä¸€å¾…æœƒä½ åšç·´ç¿’çš„æ™‚å€™ä½ æƒ³è¦ç•¶å ´éŒ„è£½å¹¾å€‹åŒå­¸çš„è²éŸ³ä½†æ˜¯ä¸çŸ¥é“è¦æ€éº¼æ¨£éŒ„æ¯”è¼ƒå¥½ä½ å¯ä»¥è€ƒæ…®é€™å€‹\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "openai.api_key = \"OpenAI\"\n",
        "prompt_summary = f\"\"\"\n",
        "ä»¥ä¸‹æ˜¯å·²ç¶“åŠ ä¸Šä¸­æ–‡æ¨™é»çš„è½‰éŒ„å…§å®¹ï¼Œè«‹å¹«æˆ‘æ¿ƒç¸®æˆ 2 å¥é‡é»æ‘˜è¦ï¼Œä¸¦ç”¨ä¸­æ–‡å®Œæ•´æ¨™é»ï¼š\n",
        "{punctuated}\n",
        "\"\"\"\n",
        "res2 = openai.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=[{\"role\": \"user\", \"content\": prompt_summary}]\n",
        ")\n",
        "summary = res2.choices[0].message.content.strip()\n",
        "print(\"=== 1â€“3 å¥é‡é»æ‘˜è¦ ===\")\n",
        "print(summary)\n"
      ],
      "metadata": {
        "id": "t2HmK3X6oghk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ä½ è¦ºå¾—èªéŸ³è½‰æ–‡å­—çš„æº–ç¢ºåº¦å¦‚ä½•ï¼Ÿæœ‰å“ªäº›åœ°æ–¹è¾¨è­˜å¾—ä¸å¤ å¥½ï¼Ÿå¯èƒ½åŸå› æ˜¯ä»€éº¼ï¼Ÿ\n",
        "ç”Ÿæˆçš„æ‘˜è¦æœ‰æŠ“åˆ°é‡é»å—ï¼Ÿå“ªäº›åœ°æ–¹å¯ä»¥æ”¹é€²ï¼Ÿ\n",
        "\n",
        "1.\n",
        "ã€ŒMel spectrogramã€è¢«èª¤è½æˆã€ŒMayerå¹³è­œã€ï¼šå°ˆæ¥­è¡“èªæ²’åœ¨æ¨¡å‹åŸå§‹è©åº«ï¼ŒåŠ ä¸Šä¸­è‹±å¤¾é›œï¼Œæ¨¡å‹é¸äº†éŸ³è¿‘çš„æ‹¼æ³•ã€‚\n",
        "ã€ŒAudacityã€è¢«è½‰ç‚ºã€ŒOdacityã€ï¼šåŒæ¨£æ˜¯å¤–æ–‡è»Ÿé«”åç¨±ï¼Œç¼ºä¹èƒŒæ™¯çŸ¥è­˜å°è‡´èª¤åˆ¤ã€‚\n",
        "ç¼ºå°‘æ¨™é»èˆ‡æ®µè½é‚Šç•Œï¼šæ•´æ®µæ˜¯ä¸€æ¢é•·å¥ï¼Œæ²’æœ‰é€—è™Ÿã€å¥è™Ÿï¼Œé›£ä»¥åˆ†è¾¨èªå¥çµæ§‹ï¼Œå½±éŸ¿é–±è®€å’Œå¾ŒçºŒæ‘˜è¦ã€‚\n",
        "\n",
        "2.\n",
        "æ‘˜è¦ç¤ºä¾‹æˆåŠŸæç…‰å‡ºï¼š\n",
        "\n",
        "ã€Œæ•¸ä½åŒ–â†’æ¢…çˆ¾é »è­œâ†’æ¨¡å‹ç”¢å‡ºæ–‡å­—ã€çš„æµç¨‹æ­¥é©Ÿï¼›\n",
        "ã€ŒAudacityã€ä½œç‚ºå…è²»éŒ„éŸ³å‰è™•ç†å·¥å…·çš„æ¨è–¦ã€‚å¯æ˜¯é‚„æ˜¯æ²’æœ‰æŠŠå°ˆæœ‰åè©è£œé½Šã€‚\n",
        "\n",
        "3.\n",
        "æ”¹é€²å»ºè­°\n",
        "å¾®èª¿ ASR è©åº«ï¼šåŠ å…¥è‡ªè¨‚whitelistï¼ˆMel spectrogramã€Audacityï¼‰ï¼Œæˆ–å¾Œè™•ç†ç”¨æ­£å‰‡è‡ªå‹•æ ¡æ­£ã€‚"
      ],
      "metadata": {
        "id": "2Kw9FBGdrsfd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ğŸ™ï¸ ä»»å‹™äºŒï¼šè²éŸ³å…‹éš†ï¼ˆVoice Cloningï¼‰ï¼ˆ50%)\n",
        "\n",
        "### ğŸ“Œ ä»»å‹™èªªæ˜ï¼š\n",
        "è«‹ä½¿ç”¨ä½ è‡ªå·±çš„èªéŸ³æ¨£æœ¬é€²è¡Œã€Œè²éŸ³å…‹éš†ã€ï¼Œè®“ AI æ¨¡ä»¿ä½ çš„è²éŸ³è¬›å‡ºæ–°çš„å¥å­ã€‚\n",
        "\n",
        "#### ä»»å‹™æ­¥é©Ÿï¼š\n",
        "1. éŒ„è£½ä¸€æ®µè‡ªå·±çš„èªéŸ³æ¨£æœ¬ï¼ˆ5ï½10 ç§’ï¼Œèªå¥è‡ªç”±ç™¼æ®ï¼‰\n",
        "2. é¸æ“‡å…©å€‹ä¸åŒçš„è²éŸ³å…‹éš†å·¥å…·ï¼ˆä¾‹å¦‚ï¼š`Tortoise TTS`ã€`Coqui TTS`ï¼‰\n",
        "3. ä½¿ç”¨é€™å…©å€‹å·¥å…·åˆ†åˆ¥æ¨¡ä»¿ä½ çš„è²éŸ³ï¼Œè®“ AI èªªå‡ºä½ è‡ªè¨‚çš„ä¸€æ®µæ–°å¥å­  \n",
        "4. æ¯”è¼ƒå…©ç¨®å·¥å…·çš„æ•ˆæœ\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ“¤ ä½œæ¥­ç¹³äº¤å…§å®¹ï¼š\n",
        "\n",
        "#### ä¸€ã€åŸå§‹èªéŸ³æ¨£æœ¬ï¼ˆéŸ³æª”ï¼‰\n",
        "\n",
        "#### äºŒã€å…©å€‹æ¨¡å‹ç”Ÿæˆçš„æ¨¡ä»¿èªéŸ³ï¼ˆéŸ³æª”ï¼‰\n",
        "\n",
        "#### ä¸‰ã€å›ç­”å•é¡Œï¼š\n",
        "\n",
        "- AI åˆæˆçš„è²éŸ³å’Œä½ çš„è²éŸ³æœ‰å¤šåƒï¼Ÿ\n",
        "- é€™å…©å€‹æ¨¡å‹æœ‰ä»€éº¼å·®ç•°ï¼Ÿå“ªä¸€å€‹è¡¨ç¾æ¯”è¼ƒå¥½ï¼Ÿç‚ºä»€éº¼ï¼Ÿ\n",
        "- å“ªäº›éƒ¨åˆ†å¯ä»¥é€²ä¸€æ­¥æ”¹é€²ï¼Ÿ"
      ],
      "metadata": {
        "id": "-H6KyBpSqiK2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture install_logs\n",
        "!apt install ffmpeg\n",
        "!pip install autoawq ffmpeg wavio\n",
        "!pip install gradio\n",
        "!pip install f5-tts # https://github.com/SWivid/F5-TTS/tree/main"
      ],
      "metadata": {
        "id": "qZrS-M0LRShC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!f5-tts_infer-gradio --share # å•Ÿå‹• Gradio ä»‹é¢"
      ],
      "metadata": {
        "id": "6skdvQmzXQu2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# å®‰è£ Tortoise TTS åŠç›¸ä¾å¥—ä»¶ï¼ˆColab å»ºè­°ç”¨ GPUï¼‰\n",
        "!pip install git+https://github.com/neonbjb/tortoise-tts.git\n",
        "!pip install einops==0.6.0\n",
        "!pip install transformers==4.29.2"
      ],
      "metadata": {
        "id": "7YuVe3HhXx7w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/neonbjb/tortoise-tts.git\n",
        "!pip install ./tortoise-tts\n",
        "!pip install einops==0.6.0\n",
        "!pip install transformers==4.29.2\n",
        "\n",
        "# ä¸‹è¼‰ tokenizer\n",
        "!wget -O tortoise-tts/tortoise/data/tokenizer.json https://huggingface.co/neonbjb/tortoise-tts/resolve/main/tokenizer.json"
      ],
      "metadata": {
        "id": "JC5C-kjSakkf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('tortoise-tts')"
      ],
      "metadata": {
        "id": "wzEpsIvjavU8"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "# ä¸Šå‚³ä½ éŒ„çš„ .wav æª”ï¼Œmy_sample.wav"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77
        },
        "id": "HEUC0duWX0ie",
        "outputId": "f00e704c-fc16-43f4-9f2e-d131d4baf59b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-06f117d0-905a-40b4-be25-d243a3d4cefa\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-06f117d0-905a-40b4-be25-d243a3d4cefa\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving my_sample.wav.wav to my_sample.wav.wav\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from tortoise.api import TextToSpeech\n",
        "from tortoise.utils.audio import load_voice\n",
        "\n",
        "# è¨­å®šé‹ç®—è£ç½®\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# åˆå§‹åŒ– Tortoise TTS\n",
        "tts = TextToSpeech(\n",
        "    use_deepspeed=False,\n",
        "    autoregressive_batch_size=1,\n",
        "    diffusion_iterations=20,\n",
        "    half=False\n",
        ")\n",
        "\n",
        "# è¼¸å…¥ä½ çš„èªéŸ³æ¨£æœ¬æª”å\n",
        "voice_samples = load_voice('my_sample.wav')   # æª”åä¾ä½ ä¸Šå‚³çš„ç‚ºæº–\n",
        "\n",
        "# ä½ è¦è®“ AI èªªçš„å¥å­\n",
        "sentence = \"æœªä¾†æ˜¯å±¬æ–¼æ‡‚ AI çš„äººï¼Œæˆ‘å·²ç¶“é–‹å§‹è¡Œå‹•äº†ã€‚\"\n",
        "\n",
        "# åˆæˆèªéŸ³\n",
        "gen = tts.tts_with_preset(\n",
        "    sentence,\n",
        "    voice_samples=voice_samples,\n",
        "    preset='fast'  # å¯é¸ 'fast' æˆ– 'standard'\n",
        ")\n",
        "\n",
        "# è¼¸å‡ºéŸ³æª”\n",
        "from scipy.io.wavfile import write as write_wav\n",
        "write_wav('tortoise_output.wav', 24000, gen.squeeze().cpu().numpy())\n",
        "print(\"åˆæˆå®Œæˆï¼Œæª”æ¡ˆï¼štortoise_output.wav\")\n"
      ],
      "metadata": {
        "id": "S6BMMVJpX37R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('tortoise_output.wav')\n"
      ],
      "metadata": {
        "id": "odxxdz6JX6HF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. åˆå§‹åŒ– Tortoise TTS\n",
        "from tortoise.api import TextToSpeech\n",
        "from tortoise.utils.audio import load_audio\n",
        "tts = TextToSpeech()\n",
        "\n",
        "# 2. è¼‰å…¥ä½ çš„è²éŸ³æ¨£æœ¬\n",
        "voice_samples = [load_audio('my_sample.wav', 22050)]  # æª”åå°æ‡‰ä½ ä¸Šå‚³çš„\n",
        "\n",
        "# 3. è¼¸å…¥ä½ è¦è®“ AI è¬›çš„å¥å­\n",
        "sentence = \"æœªä¾†æ˜¯å±¬æ–¼æ‡‚ AI çš„äººï¼Œæˆ‘å·²ç¶“é–‹å§‹è¡Œå‹•äº†ã€‚\"\n",
        "\n",
        "# 4. åˆæˆèªéŸ³\n",
        "gen = tts.tts_with_preset(\n",
        "    sentence,\n",
        "    voice_samples=voice_samples,\n",
        "    conditioning_latents=None,\n",
        "    preset='fast'\n",
        ")\n",
        "\n",
        "# 5. å„²å­˜éŸ³æª”\n",
        "from scipy.io.wavfile import write as write_wav\n",
        "write_wav('tortoise_output.wav', 24000, gen.squeeze().cpu().numpy())\n",
        "print(\"åˆæˆå®Œæˆï¼Œæª”æ¡ˆï¼štortoise_output.wav\")\n"
      ],
      "metadata": {
        "id": "w7yesaJuZ81g"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}